\section{Searching for Gravitational Waves using Neural Networks}
%\textcolor{blue}{List papers and their findings, that belong in the same area and/or had influence on this work.}\\
\textcolor{red}{Put motivation here}\\
\textcolor{blue}{Motivate why the problem we are looking at is interesting and why it might be beneficial to train for SNR instead of simply classifying. Why is BNS more difficult? (Care, I think I wrote a little bit about this in the Data Generating Process section) Maybe drop this if the motivation is clear from the introduction and related works section.}\\
With the rise in popularity of \gls{nns}, machine learning techniques were applied to a wide range of problems. One of these is the \gls{gw} data-analysis where it has found multiple applications.\\
The use off deep neural networks as a filter to detect \gls{gw}-signals in noisy detector data was pioneered by Daniel George and E.A. Huerta \cite{original_deep_filtering}. They used a \gls{cnn} to classify time series data into the two categories ''noise + signal'' and ''pure noise'' as well estimate some source parameters for \gls{bbh} signals. The network was able to closely reproduce the results a classical matched filter search could achieve and even showed potential to adapt to eccentric signals which were not used during the training stage. The followup paper \cite{huerta_parameter_estimation} used real instead of simulated detector noise, demonstrating that \gls{cnns} can be used for real time classification and parameter estimation.\\
A similar concept has been applied to the search for continuous \gls{gw} in \cite{paper_christoph}. The authors show that for a relatively short observation time the performance of their network on low frequency data rivals that of matched filtering, while for higher frequencies or longer observation times their approach falls off. The key advantage of this search is the computational efficiency. Using \gls{cnns} reduces the pure search time by several orders of magnitude. Even including the time spent during training and for a necessary followup search seems to reduce the total computational cost. However the authors don't get more specific in that regard.\\
The recently published paper \cite{bns_network} claims to be able to differentiate between the three classes ''noise'', ''\gls{bbh}-signal'' and ''\gls{bns}-signal'', by using a whitened time series of \SI{2}{\s} duration. We question their results in multiple aspects based on out own research. First of all, their validation and testing set contains only 5000 samples, with a split of only $1/3$ being pure noise samples. From so few samples it is difficult to get a good estimate of the false alarm rate, due to the lack of noise realizations. This is one of the possibly many factors that lead to their quoted 0\% false alarm probability for \gls{bns} and 1\% for \gls{bbh} signals. Furthermore, they shift their signals around the data by \SI{\pm 0.1}{\s}. With $1667$ noise samples this leads to a false alarm rate of \SI[per-mode=fraction]{\sim 15500}{\samples\per\month} for their loudest noise instance\footnote{We calculated this number as explained below equation \eqref{def:false_alarm_rate}}. Secondly, they only calculate their results in terms of peak signal-to-noise ratio and quote a matched filter signal-to-noise ratio of 13 times the peak signal-to-noise ratio. However, using our own data, we found that a matched filter \gls{snr} of $\sim 15$ corresponds to a peak \gls{snr} of $0.2$. Using our conversion of peak \gls{snr} to matched filter \gls{snr}, their network has a sensitivity below 10\% at matched filter \gls{snr} 15. Considering the results of this thesis and the architecture they used, these results sound consistent to our findings. (compare the start of \autoref{sec:evolution_of_architecture})\smallskip\\
\cite{cnn_magiacal_bullet} aims to reduce the confusion that occurs when mixing terms of computer science with those of gravitational data analysis. It criticizes the way statistical significance is claimed by different machine learning approaches. It especially claims that no statistical meaningful false alarm rate can be derived from \gls{nns} using only training, validation and testing set, if these sets contained individual samples of pure noise and signals. They base their criticism on the fact that a sliding window approach will not always contain the signals in the way the training set suggests. The waveform will not be positioned in just the way it was during the training stage but at some uncontrollable point. Due to this limitation they say that \gls{nns} can only be used as quick and reliable trigger generators that need a followup matched filter search. We try to address most of their points by generating all results from a long continuous time series. All triggers that are generated on this test set will use a fixed threshold that was determined on the validation set. Further measures and precautions will be explained in \autoref{sec:network_performance}.\\
A major contribution relating the architecture came from \cite{tcn_idea}, who compared the performance of multiple different general architectures in the field of gravitational wave data analysis. Their findings indicated that a \gls{tcn} was the best algorithm. They were also able to compare current feed forward neural networks against recurrent neural networks in the scope of \gls{gw} data analysis and concluded that they in some cases outperform \gls{cnn} architectures but can't match their \gls{tcn}.\\
\cite{dnn_denoising} takes a similar approach to their network architecture as \cite{tcn_idea} does but uses it to denoise the input data, i.e. recover the waveform from the noisy detector data. They show that the network is able to recover \gls{bbh} signals to incredible accuracy and thus can learn the characteristics of the noise background. We use their idea as part of our final network.