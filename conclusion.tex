\section{Conclusions}
\begin{comment}
\textcolor{blue}{Well duh, give a conclusion and maybe outlook.}\\
\textcolor{red}{Mention that the PyCBC Live pipeline has probably (talk to Alex about this) a higher latency than our search (they have latency on average \SI{16}{\s} \cite{pycbc_live}) but already give rough parameter estimation and sky localization which we can't do. They furthermore are a lot more sensitive.}
\begin{itemize}
	\item First time anybody tested sensitivity of a \gls{nn} for \gls{bns} signals at such a low false alarm rate
	\item Computationally very efficient therefore lower latency (need to quantify this)
	\item At the moment network probably too complicated and therefore hyper parameters probably not optimal
	\item Introduced new architecture of using a TCN as denoiser. Also the cascading architecture is new and promising
	\item Network not yet ready to use
	\item Couldn't work with real detector data yet, as it also wouldn't be sensible with our sensitivity
	\item Still interesting as it has shown potential with easier data
\end{itemize}
\end{comment}
This work has explored a completely new set of architectures in their application to \gls{gw} data analysis. We introduced the concept of using multiple sample rates to reduce the number of input samples to the network and thus decrease the size of the network, while retaining a lot of the information of the long signals that are emitted by \gls{bns} systems. Testing multiple different architectures led to the use of inception modules and the \gls{tcn}s as amplifiers for the input signal. Our design process led to a very deep and wide architecture utilizing multiple techniques pioneered for image recognition tasks. To the best of our knowledge we are also the first to use the \gls{snr} as a training goal, thus providing a direct ranking statistic for every event.\\
We have for the first time tested the sensitivity of a \gls{nn}-based search at very low false alarm rates for \gls{bns} signals. The final architecture suggests that it might be possible to reach meaningful false alarm rates that are low enough to alert astronomers of possible \gls{gw} events. Though we have not managed to fully reach the goal of acceptable sensitivities at a false alarm rate of \SI[per-mode=fraction]{1}{\sample\per\month}, our network significantly improves upon previously tested architectures.\\
We do, however, find that a search pipeline using our \gls{nn} to detect \gls{bns} signals is not yet sensible. Current matched filter pipelines are superior in every aspect. Not only are they more sensitive to the signals we used to train our network, but are also computationally more efficient, which was the main reason to explore machine learning search pipelines. The gap in efficiency is mostly down to the high complexity of the final architecture. We furthermore did not test the sensitivity of the network on real detector data which contains non Gaussian noise transients and can thus not claim any implications for a real search.\\
Using the \gls{snr} as training goal has proven to be a difficult problem. Using it to generate detection candidates yields slightly worse sensitivities at low false alarm rates. At high false alarm rates this difference vanishes. We did, however, find that this output is a lot more fragile and can produce realistic detection values for unrelated data. The p-score is a lot more resilient to such inputs and can also be interpreted as a ranking statistic, rather than a binary output.\\
We hope that our work, although not yielding a useful search pipeline, will prove useful to the field of utilizing machine learning algorithm to detect \gls{gw}s. This thesis has tested multiple new approaches to the architecture and has found great improvements over the current state of the art convolutional architectures, by deploying inception modules. We have furthermore given an overview of a process which we believe produces reliable estimates of false alarm rates and sensitivities by sliding our network across a continuous input.\smallskip\\
As a next step we would like to decrease the complexity of our architecture while retaining its sensitivity. Doing so would yield better computational efficiency and enable us to do more efficient hyper parameter exploration, which in turn will hopefully improve the performance even further. We also want to test different formats for the input data, as others have used shorter parts but sampled at a higher rates. Finally, as a long term goal, we would like to incorporate and test real detector data and turn this approach into an independent search pipeline. To give security against data that accidentally resonates strongly with the network this pipeline should be backed up by a matched filter pipeline that only covers a small parameter space.
